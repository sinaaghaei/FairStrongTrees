names(tmp1) <- c("approach","depth","fair.bound","acc","disc",'source')
tmp2 <- tmp[,c("approach","depth","fair.bound","train.acc","train.disc")]
tmp2$source <- 'in-sample'
names(tmp2) <- c("approach","depth","fair.bound","acc","disc",'source')
tmp <- rbind(tmp1,tmp2)
rm(tmp1,tmp2)
data_flow_limited <- tmp
data_flow_limited$data <- NULL
data_flow_limited$approach <- "FlowOCT (limited)"
rm(tmp,data)
data= read.csv('./../Results/Kamiran/compas.csv', header=TRUE, sep=',', na.strings="", stringsAsFactors =TRUE)
data$depth <- data$depth + 1
data <- data %>%
group_by(depth, fair.bound) %>%
summarise(mean(acc_tr_pre),mean(disc_tr_pre),mean(acc_te_pre), mean(disc_te_pre),
mean(train.acc),mean(sp.train.pred),mean(test.acc),mean(sp.test.pred))
names(data) <- c("depth","fair.bound",'acc_tr_pre','disc_tr_pre','acc_te_pre','disc_te_pre','train.acc','sp.train.pred','test.acc','sp.test.pred')
data$approach <- 'DADT'
data_relab <- data[,c('approach','depth','fair.bound','train.acc','sp.train.pred','test.acc','sp.test.pred')]
# data_relab$approach <- 'Kamiran_relab'
data_relab_train <- data_relab[,c('approach','depth','fair.bound','train.acc','sp.train.pred')]
data_relab_train$source <- 'in-sample'
names(data_relab_train) <- c('approach','depth','fair.bound','acc','disc','source')
data_relab_test <- data_relab[,c('approach','depth','fair.bound','test.acc','sp.test.pred')]
data_relab_test$source <- 'out-of-sample'
names(data_relab_test) <- c('approach','depth','fair.bound','acc','disc','source')
data_relab <- rbind(data_relab_train, data_relab_test)
rm(data_relab_test, data_relab_train)
data_pre <- data[,c('approach','depth','fair.bound','acc_tr_pre','disc_tr_pre','acc_te_pre','disc_te_pre')]
data_pre_train <- data_pre[,c('approach','depth','fair.bound','acc_tr_pre','disc_tr_pre')]
data_pre_train$source <- 'in-sample'
names(data_pre_train) <- c('approach','depth','fair.bound','acc','disc','source')
data_pre_test <- data_pre[,c('approach','depth','fair.bound','acc_te_pre','disc_te_pre')]
data_pre_test$source <- 'out-of-sample'
names(data_pre_test) <- c('approach','depth','fair.bound','acc','disc','source')
data_pre <- rbind(data_pre_train, data_pre_test)
rm(data_pre_test, data_pre_train, data)
data_pre$fair.bound <- 1
data_pre <- unique(data_pre)
# data_kamiran <- rbind(data_pre, data_relab)
data_kamiran <- data_relab
rm(data_pre, data_relab)
data_kamiran$acc <- data_kamiran$acc/100
data <- rbind(data_flow, data_kamiran, data_flow_limited)
data <- subset(data, data$fair.bound %in% data_kamiran$fair.bound)
data$approach <- as.factor(data$approach)
data$approach<- factor(data$approach, levels = c("FlowOCT","FlowOCT (limited)","DADT"))
t_depth = 3
t_source = 'in-sample'
tmp <- subset(data,data$depth ==t_depth & data$source == t_source)
x_title = ""
y_title= ""
legend_title = 'SP Bound'
g1 <- ggplot(tmp,aes(x=((disc))*100, y=acc*100)) +
geom_line(aes(linetype=approach), size=3) +
geom_point(aes(color = fair.bound),size=10)+
scale_color_gradient(low="blue", high="red")+
scale_linetype_manual(values=c(1,3,2))+
labs(x=x_title, y = y_title, linetype = "Data", color =legend_title)+
xlim(-7, 17)+
ylim(50, 85)+
theme(
# plot.title = element_text(size = 25),
axis.text = element_text(size = 45),
legend.position = "right", legend.key.size = unit(1, "cm"),
legend.text = element_text(size = 30),
legend.title = element_text(size = 35),
text = element_text(family=fontfam),
axis.title = element_text(size = 40)
)
print(g1)
fig_name = paste('1vs1_',data_name,'_depth_',t_depth,'_', t_source,'.pdf', sep = '')
ggsave(paste(figure_path,fig_name,sep = ""),device = "pdf", width = 16, height = 12, units =  "in")
t_source = 'out-of-sample'
tmp <- subset(data,data$depth ==t_depth & data$source == t_source)
x_title = ""
y_title= ""
legend_title = 'SP Bound'
g1 <- ggplot(tmp,aes(x=((disc))*100, y=acc*100)) +
geom_line(aes(linetype=approach), size=3) +
geom_point(aes(color = fair.bound),size=10)+
scale_color_gradient(low="blue", high="red")+
scale_linetype_manual(values=c(1,3,2))+
labs(x=x_title, y = y_title, linetype = "Data", color =legend_title)+
xlim(-7, 17)+
ylim(50, 85)+
theme(
# plot.title = element_text(size = 25),
axis.text = element_text(size = 45),
legend.position = "right", legend.key.size = unit(1, "cm"),
legend.text = element_text(size = 30),
legend.title = element_text(size = 35),
text = element_text(family=fontfam),
axis.title = element_text(size = 40)
)
print(g1)
fig_name = paste('1vs1_',data_name,'_depth_',t_depth,'_', t_source,'.pdf', sep = '')
ggsave(paste(figure_path,fig_name,sep = ""),device = "pdf", width = 16, height = 12, units =  "in")
# if (forpres)
# {
#   ggsave(paste(figure_path,fig_name,sep = ""),device = "pdf", width = 16, height = 12, units =  "in")
# } else {
#   ggsave(paste(figure_path,fig_name,sep = ""),device = "pdf", width = 12, height = 8, units =  "in")
# }
t_depth = 3
t_source = 'in-sample'
tmp <- subset(data,data$depth ==t_depth & data$source == t_source)
x_title = ""
y_title= ""
legend_title = 'SP Bound'
g1 <- ggplot(tmp,aes(x=((disc))*100, y=acc*100)) +
geom_line(aes(linetype=approach), size=3) +
geom_point(aes(color = fair.bound),size=10)+
scale_color_gradient(low="blue", high="red")+
scale_linetype_manual(values=c(1,3,2))+
labs(x=x_title, y = y_title, linetype = "Data", color =legend_title)+
# xlim(-7, 17)+
# ylim(50, 85)+
theme(
# plot.title = element_text(size = 25),
axis.text = element_text(size = 45),
legend.position = "right", legend.key.size = unit(1, "cm"),
legend.text = element_text(size = 30),
legend.title = element_text(size = 35),
text = element_text(family=fontfam),
axis.title = element_text(size = 40)
)
print(g1)
fig_name = paste('1vs1_',data_name,'_depth_',t_depth,'_', t_source,'.pdf', sep = '')
ggsave(paste(figure_path,fig_name,sep = ""),device = "pdf", width = 16, height = 12, units =  "in")
t_source = 'out-of-sample'
tmp <- subset(data,data$depth ==t_depth & data$source == t_source)
x_title = ""
y_title= ""
legend_title = 'SP Bound'
g1 <- ggplot(tmp,aes(x=((disc))*100, y=acc*100)) +
geom_line(aes(linetype=approach), size=3) +
geom_point(aes(color = fair.bound),size=10)+
scale_color_gradient(low="blue", high="red")+
scale_linetype_manual(values=c(1,3,2))+
labs(x=x_title, y = y_title, linetype = "Data", color =legend_title)+
# xlim(-7, 17)+
# ylim(50, 85)+
theme(
# plot.title = element_text(size = 25),
axis.text = element_text(size = 45),
legend.position = "right", legend.key.size = unit(1, "cm"),
legend.text = element_text(size = 30),
legend.title = element_text(size = 35),
text = element_text(family=fontfam),
axis.title = element_text(size = 40)
)
print(g1)
fig_name = paste('1vs1_',data_name,'_depth_',t_depth,'_', t_source,'.pdf', sep = '')
ggsave(paste(figure_path,fig_name,sep = ""),device = "pdf", width = 16, height = 12, units =  "in")
# if (forpres)
# {
#   ggsave(paste(figure_path,fig_name,sep = ""),device = "pdf", width = 16, height = 12, units =  "in")
# } else {
#   ggsave(paste(figure_path,fig_name,sep = ""),device = "pdf", width = 12, height = 8, units =  "in")
# }
data= read.csv('./../Results/Dec 29/FlowOCT Kamiran_version/Kamiran_compas-limited.csv', header=FALSE, sep=',', na.strings="", stringsAsFactors =TRUE)
data_name = 'compas'
header= read.csv('./../header_kamiran.csv', header=TRUE, sep=',', na.strings="", stringsAsFactors =TRUE)
names(data) <- names(header)
rm(header)
data$sample <- as.factor(data$sample)
# data$depth <- as.factor(data$depth)
data$fair.type <- as.factor(data$fair.type)
data$fair.bound <- as.factor(data$fair.bound)
tmp_none <- data[data$fair.type == 'None',]
tmp_none$fair.type = 'SP'
data = rbind(data,tmp_none)
data <- data[data$fair.type!= 'None',]
data$fair.type <- droplevels(data$fair.type)
rm(tmp_none)
View(data)
summary(data$solving.time)
1956.8/3600
5245.7/3600
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE,message = FALSE,warning = FALSE )
library(kableExtra)
library(png)
library(ggplot2)
library(reshape2)
library(egg)
require(tidyr)
require(dplyr)
library(dplyr)
library(latex2exp)
# library(ggpubr)
library(data.table)
library(RColorBrewer)
library(MASS)
require(scales)
library(tidyverse)
library(dplyr)
rm(list = ls())
cat("\014")
graphics.off()
vispdat <- read.csv("./Data/vispdat_sina.csv")
knitr::opts_chunk$set(echo = TRUE,message = FALSE,warning = FALSE )
library(kableExtra)
library(png)
library(ggplot2)
library(reshape2)
library(egg)
require(tidyr)
require(dplyr)
library(dplyr)
library(latex2exp)
# library(ggpubr)
library(data.table)
library(RColorBrewer)
library(MASS)
require(scales)
library(tidyverse)
library(dplyr)
rm(list = ls())
cat("\014")
graphics.off()
vispdat <- read.csv("./Data/vispdat_sina.csv")
knitr::opts_chunk$set(echo = TRUE,message = FALSE,warning = FALSE )
library(kableExtra)
library(png)
library(ggplot2)
library(reshape2)
library(egg)
require(tidyr)
require(dplyr)
library(dplyr)
library(latex2exp)
# library(ggpubr)
library(data.table)
library(RColorBrewer)
library(MASS)
require(scales)
library(tidyverse)
library(dplyr)
rm(list = ls())
cat("\014")
graphics.off()
vispdat <- read.csv("./../Data/vispdat_sina.csv")
singles = read.csv("./../Data/One-drive/SingleAdultWideForm_VI_MoveIn.csv",na.strings=c("",NA))
singles = singles[!is.na(singles$FirstAssessDate), ]
singles <- singles[order(singles$PersonalID),c('PersonalID','FirstAssessDate')]
vispdat <- vispdat[,c('PersonalID','assessment_date','Race', 'Gender','VeteranStatus','DOBYear','age','score','score_ad','score_sus')]
enrollments <- read.csv("./../Data/One-drive/EnrollMergedClaritySingles_VI_Assess.csv",na.strings=c("",NA))
enrollments <- enrollments[,c('PersonalID', 'EnrollmentID', 'Treatment' ,'EntryDate', 'MoveInDate' )] #'ProjectID', 'CPL_ProjectTypeName', 'CPL_ProjectTypeCategory' ,'HousingTypeName'
names(enrollments)[names(enrollments) == 'EntryDate'] = 'EnrollDate'
names(enrollments)[names(enrollments) == 'Treatment'] = 'EnrollProj'
closestAssessment <- read.csv("./../Data/One-drive/EnrollMergedClaritySingles_VI_Assess_ClosestAssess.csv",na.strings=c("",NA))
closestAssessment <- closestAssessment[,c('PersonalID', 'EnrollmentID','CloseAssessDate_Entry' )]
closestAssessment <- na.omit(closestAssessment)
enrollments <- merge(enrollments, closestAssessment, by = c('PersonalID', 'EnrollmentID'))
names(enrollments)[names(enrollments)=='CloseAssessDate_Entry'] = 'CloseAssessDate_Enroll'
rm(closestAssessment)
tmp <- merge(enrollments, singles, by = 'PersonalID')
#Now we remove those lines that EnrollDate is before the first-assessment-date
tmp <- subset(tmp, tmp$EnrollDate >= tmp$FirstAssessDate) #| abs(as.numeric(as.Date(tmp$EnrollDate) - as.Date(tmp$FirstAssessDate)))<=10
#We also keep only those assessment dates that are after 2016-01-01
tmp <- subset(tmp, as.Date(tmp$FirstAssessDate) >= '2016-01-01')
tmp <- tmp[order(tmp$EnrollmentID), ]
tmp <- tmp[order(tmp$EnrollDate), ]
tmp <- tmp[order(tmp$PersonalID), ]
index <- tmp$EnrollProj == 'PH_Other'
tmp$EnrollProj[index] = 'NotTr'
index <- tmp$EnrollProj == 'NotTr' & !is.na(tmp$MoveInDate)
tmp$MoveInDate[index] = NA
tmp$MoveInProj <- 'NotTr'
index <- !is.na(tmp$MoveInDate)
tmp$MoveInProj[index] = tmp$EnrollProj[index]
singles_new <- tmp
rm(tmp, enrollments)
singles_new <- singles_new[,c('PersonalID','EnrollProj','EnrollDate','MoveInProj','MoveInDate','FirstAssessDate','CloseAssessDate_Enroll')]
# We remove those 29 people that the moveInDate is before the EnrollDate
singles_new <- subset(singles_new,  (is.na(singles_new$MoveInDate) )| (!is.na(singles_new$MoveInDate) & as.Date(singles_new$MoveInDate) >= as.Date(singles_new$EnrollDate)) )
rm(singles)
View(singles_new)
View(singles_new)
vispdat <- vispdat[order(vispdat$assessment_date,decreasing = TRUE),]
vispdat <- vispdat[order(vispdat$PersonalID),]
#First if for a given person we have two assessment in the same day, we keep only one of them
vispdat <- vispdat %>%
group_by(PersonalID,assessment_date) %>%
mutate(pindex2 = 1:n())
vispdat <- vispdat[vispdat$pindex2==1,]
vispdat$pindex2 <- NULL
# vispdat_latest = vispdat
# vispdat_latest <- vispdat_latest %>%
#   group_by(PersonalID) %>%
#   mutate(pindex = 1:n())
# vispdat_latest <- vispdat_latest[vispdat_latest$pindex==1,]
# vispdat_latest$pindex <- NULL
#
# analysis <- merge(x= singles_new, y = vispdat, by.x = c('PersonalID','CloseAssessDate_Enroll'), by.y = c('PersonalID','assessment_date'))
# vispdat_latest <- subset(vispdat_latest, !(vispdat_latest$PersonalID %in% analysis$PersonalID) & (vispdat_latest$PersonalID %in% singles_new$PersonalID))
# tmp <- subset(singles_new, singles_new$PersonalID %in% vispdat_latest$PersonalID)
# tmp <- merge(x= tmp, y = vispdat_latest, by.x = 'PersonalID')
# tmp$CloseAssessDate_Enroll <- tmp$assessment_date
# tmp$assessment_date <- NULL
# tmp <- tmp[,names(analysis)]
# analysis <- rbind(analysis, tmp)
# rm(tmp,vispdat_latest)
#First for each individual we need to find the assessment in vispdat which corresponds to cloesestAssessment_Enroll in singles_new
analysis <- merge(x= singles_new, y = vispdat, by.x = c('PersonalID','CloseAssessDate_Enroll'), by.y = c('PersonalID','assessment_date'))
length(unique(analysis$PersonalID)) == nrow(analysis)
analysis$FirstAssessDate <- as.Date(analysis$FirstAssessDate )
analysis$MoveInDate <- as.Date(analysis$MoveInDate)
analysis$EnrollDate <- as.Date(analysis$EnrollDate)
analysis$CloseAssessDate_Enroll <- as.Date(analysis$CloseAssessDate_Enroll)
for(f in c('PersonalID', 'MoveInProj', 'EnrollProj', 'Race', 'Gender', 'VeteranStatus')){
analysis[[f]] <- as.factor(analysis[[f]])
}
# Add score categories #
analysis$scorecat = NA
index = with(analysis, analysis$score>=0 & analysis$score<4)
analysis$scorecat[index] = "low"
index = with(analysis, analysis$score>=4 & analysis$score<8)
analysis$scorecat[index] = "mid"
index = with(analysis, analysis$score>=8 & analysis$score<12)
analysis$scorecat[index] = "mid-high"
index = with(analysis, analysis$score>=12)
analysis$scorecat[index] = "high"
# write.csv(analysis, "analysis.csv", row.names = FALSE)
View(analysis)
analysis_w <- analysis
analysis_w <- subset(analysis_w, !(analysis_w$MoveInProj %in% c("NotTr","NA")))
View(analysis_w)
summary(analysis_w)
summary(analysis_w)
tmp <- subset(analysis_w, analysis_w$EnrollDate < analysis_w$CloseAssessDate_Enroll)
View(tmp)
tmp <- subset(analysis_w, analysis_w$EnrollDate >= analysis_w$CloseAssessDate_Enroll)
tmp <- subset(analysis_w, analysis_w$EnrollDate > analysis_w$CloseAssessDate_Enroll)
tmp <- subset(analysis_w, analysis_w$FirstAssessDate != analysis_w$CloseAssessDate_Enroll)
4194
tmp <- subset(analysis_w, analysis_w$FirstAssessDate < analysis_w$CloseAssessDate_Enroll)
tmp <- subset(analysis_w, analysis_w$FirstAssessDate < analysis_w$CloseAssessDate_Enroll)
length(unique(analysis_w$PersonalID))
library(data.table)
library(Publish)
library(caret)
library(sigmoid)
library(rpart)
library(dplyr)
rm(list=ls())
graphics.off()
Kamiran_version = TRUE
#################################################################################################
#Functions
#################################################################################################
dataencoder <- function (data) {
#encoding data
must_convert<-sapply(data,is.factor)       # logical vector telling if a variable needs to be displayed as numeric
M2<-sapply(data[,must_convert],unclass)    # data.frame of all categorical variables now displayed as numeric
data_num<-cbind(data[,!must_convert],M2)
data_num <- as.data.frame(data_num)
for(tmp_f in names(data)){
data_num[[tmp_f]] = as.factor(data_num[[tmp_f]] )
data_num[[tmp_f]]  = droplevels(data_num[[tmp_f]] )
}
data_num
}
##########################################################################################################
# read data
##########################################################################################################
# data_raw <- read.csv("compas-analysis-master/compas-scores-raw.csv", header = TRUE, sep = ",",na.strings = "",stringsAsFactors = TRUE)
# data_v <- read.csv("compas-analysis-master/compas-scores-two-years-violent.csv", header = TRUE, sep = ",",na.strings = "",stringsAsFactors = TRUE)
# data_compas <- read.csv("compas-analysis-master/compas-scores.csv", header = TRUE, sep = ",",na.strings = "",stringsAsFactors = TRUE)
setwd('/Users/sina/Documents/GitHub/FairStrongTrees/Data Proprocess code/compas/')
data <- read.csv("compas-analysis-master/compas-scores-two-years.csv", header = TRUE, sep = ",",na.strings = "",stringsAsFactors = TRUE)
#We remove decile_score, score_text from the features
data <- dplyr::select(data, race, age_cat, sex,priors_count, c_charge_degree, c_jail_in, c_jail_out, days_b_screening_arrest,
is_recid, two_year_recid) %>%
filter(days_b_screening_arrest <= 30) %>%
filter(days_b_screening_arrest >= -30) %>%
filter(is_recid != -1) %>%
filter(c_charge_degree != "O")
#  %>% filter(score_text != 'N/A')
data$length_of_stay <- as.numeric(as.Date(data$c_jail_out) - as.Date(data$c_jail_in))
data <- dplyr::select(data, race, age_cat, sex,priors_count, c_charge_degree,length_of_stay,
two_year_recid)
names(data)[names(data)=="two_year_recid"] = "target"
data$age_cat <- factor(data$age_cat, levels = c('Less than 25','25 - 45','Greater than 45'))
# data$score_text <- factor(data$score_text, levels = c('Low','Medium','High'))
# we partition prior convictions into
#four bins: 0, 1–2, 3–4, and 5 or more.
# see: https://arxiv.org/pdf/1701.08230.pdf
data$priors_count = as.numeric(data$priors_count)
data$priors_count = cut(data$priors_count ,
c(-Inf,0,2,4,Inf),
labels=c(1,2,3,4))
#5 bins: 0, 1, 2–7, 8-15,and 16 or more.
data$length_of_stay = cut(data$length_of_stay ,
c(-Inf,0,1,7,15,Inf),
labels=c(1,2,3,4,5))
index <- !(data$race %in% c('African-American','Caucasian','Hispanic'))
data$race[index] <- 'Other'
for(f in names(data)){
data[[f]] = as.factor(data[[f]])
data[[f]] = droplevels(data[[f]])
}
data$race <- as.character(data$race)
if(Kamiran_version){
index <- data$race == 'Caucasian'
data$race[index] = 'white'
data$race[!index] = 'non-white'
}
data$race <- as.factor(data$race)
##########################################################################################################
# encoding data
##########################################################################################################
data <- dataencoder(data)
data_enc = data
#Now we tuurn all categorical  features into one-hot vectors
dmy <- dummyVars(" ~ .-target", data = data_enc)
data_enc <- data.frame(predict(dmy, newdata = data_enc))
#if a feature has only two levels we should only keep one column
#As our convention, we always keep the first one
cols = c()
tmp <- gsub("\\..*","",names( data_enc ))
for(name in names(data)){
# a = grepl( name , tmp ,fixed=TRUE)
a = tmp == name
if(sum(a)==2){
cols <- append(cols, min(which(a == TRUE)))
}else{
cols <- append(cols, which(a == TRUE))
}
}
data_enc <- data_enc[,cols]
data_enc$target <- data$target
# Taking care of  the integer columns : If x_ij = 1 then x_i(j+1) should be one as well  for odd i's
features = c('age_cat','priors_count','length_of_stay')#,'score_text'
for(v in features){
for(i in seq(2,nlevels(data[[v]]),1)){
a =  as.numeric(as.character(data_enc[[paste(v,toString(i),sep = ".")]]))
b =  as.numeric(as.character(data_enc[[paste(v,toString(i-1),sep = ".")]]))
data_enc[[paste(v,toString(i),sep = ".")]] =  as.numeric(a|b)
}
}
rm(dmy)
if(Kamiran_version){
setwd('/Users/sina/Documents/GitHub/FairStrongTrees/DataSets/KamiranVersion')
}else{
setwd('/Users/sina/Documents/GitHub/FairStrongTrees/DataSets/')
}
# write.csv(data,'compas.csv',row.names = FALSE)
# write.csv(data_enc,'compas_enc.csv',row.names = FALSE)
##########################################################################################################
# Sampling from data
##########################################################################################################
seeds = c(123,156,67,1,43)
for(Run in c(1,2,3,4,5)){
## set the seed to make your partition reproducible
set.seed(seeds[Run])
##########################################################################################################
# Splitting data into training and test
##########################################################################################################
tmp <- data %>%
mutate(index = row_number()) %>%
group_by(race, priors_count, target) %>%
sample_frac(replace = FALSE, size = 0.75) %>%
ungroup()
train_ind <- tmp$index
data_test <- data[-train_ind, ]
data_test_enc <- data_enc[-train_ind, ]
tmp <- tmp %>%
sample_n(replace = FALSE, size = 850)
train_ind <- tmp$index
data_train <- data[train_ind, ]
data_train_enc <- data_enc[train_ind, ]
tmp <- data_train %>%
mutate(index = row_number()) %>%
group_by(race, priors_count, target) %>%
sample_frac(replace = FALSE, size = 2/3)
train_calibration_ind <- tmp$index
data_train_calibration <- data_train[train_calibration_ind, ]
data_calibration<- data_train[-train_calibration_ind, ]
data_train_calibration_enc <- data_train_enc[train_calibration_ind, ]
data_calibration_enc <- data_train_enc[-train_calibration_ind, ]
print('#############################')
print('******train_calibration')
# print(table(data_train_calibration$race, data_train_calibration$priors_count  , data_train_calibration$target))
print(table(data_train_calibration$race, data_train_calibration$target))
print('******train')
# print(table(data_train$race, data_train$priors_count  , data_train$target))
print(table(data_train$race, data_train$target))
print('******test')
# print(table(data_test$race, data_test$priors_count  , data_test$target))
print(table(data_test$race, data_test$target))
print('******calibration')
# print(table(data_calibration$race, data_calibration$priors_count  , data_calibration$target))
print(table(data_calibration$race, data_calibration$target))
#
# Save files
write.csv(data_train_enc,paste("compas-limited_train_enc_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_test_enc,paste("compas-limited_test_enc_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_train,paste("compas-limited_train_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_test,paste("compas-limited_test_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_train_calibration,paste("compas-limited_train_calibration_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_train_calibration_enc,paste("compas-limited_train_calibration_enc_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_calibration,paste("compas-limited_calibration_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_calibration_enc,paste("compas-limited_calibration_enc_",toString(Run),".csv",sep=''),row.names = FALSE)
}
# data_train<- read.csv("/Users/sina/Documents/GitHub/FairStrongTrees/DataSets/KamiranVersion/compas_train_calibration_1.csv", header = TRUE, sep = ",",na.strings = "",stringsAsFactors = TRUE)
# data_train_kamiran <- read.csv("/Users/sina/Documents/GitHub/FairStrongTrees/DataSets/KamiranVersion/compas_train_calibration_1.csv", header = TRUE, sep = ",",na.strings = "",stringsAsFactors = TRUE)
#
6172 - 1542
4630/6172
