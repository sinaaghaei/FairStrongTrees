data_test$t <- as.factor(as.character(data_test$t))
##########################################################################################################
# Learning propensity score P(t|x) for each entry using logestic regression
##########################################################################################################
t_train_data = data_train[,!(names(data_train) %in% c("y0","y1","y","prob_t"))]
t_test_data = data_test[,!(names(data_test) %in% c("y0","y1","y","prob_t"))]
glm.fit <- glm(t ~ ., data = t_train_data, family = "binomial")
data_train$prop_score_1 <- predict(glm.fit,newdata = t_train_data,type = "response")
data_test$prop_score_1 <- predict(glm.fit,newdata = t_test_data,type = "response")
rm(t_train_data,t_test_data)
data_train$prob_t_pred_log <- as.numeric(as.character(data_train$t))*data_train$prop_score_1 + (1-as.numeric(as.character(data_train$t)))*(1-data_train$prop_score_1)
data_train$prop_score_1 <- NULL
data_test$prob_t_pred_log <- as.numeric(as.character(data_test$t))*data_test$prop_score_1 + (1-as.numeric(as.character(data_test$t)))*(1-data_test$prop_score_1)
data_test$prop_score_1 <- NULL
rm(glm.fit)
##########################################################################################################
# Learning propensity score P(t=1|x) for each entry using decision tree
##########################################################################################################
t_train_data = data_train[,!(names(data_train) %in% c("y0","y1","y","prob_t","prob_t_pred_log"))]
t_test_data = data_test[,!(names(data_test) %in% c("y0","y1","y","prob_t","prob_t_pred_log"))]
#model <- rpart(t ~ ., data = t_train_data, method = "class", control = rpart.control(maxdepth = 4, minsplit = 20, cp=0.01))
train_control<- trainControl(method="repeatedcv", number=10, repeats = 3)
model.cv <- train(t ~ .,
data = t_train_data,
method = "rpart",
trControl = train_control)
model <- model.cv$finalModel
data_train$prop_score_1  <- predict(model, t_train_data, type = "prob")[,2]
data_test$prop_score_1  <- predict(model, t_test_data, type = "prob")[,2]
rm(t_train_data,t_test_data)
data_train$prob_t_pred_tree <- as.numeric(as.character(data_train$t))*data_train$prop_score_1 + (1-as.numeric(as.character(data_train$t)))*(1-data_train$prop_score_1)
data_train$prop_score_1 <- NULL
data_test$prob_t_pred_tree <- as.numeric(as.character(data_test$t))*data_test$prop_score_1 + (1-as.numeric(as.character(data_test$t)))*(1-data_test$prop_score_1)
data_test$prop_score_1 <- NULL
# par(xpd = TRUE)
# plot(model, compress = TRUE)
# text(model, use.n = TRUE)
#
# summary(data_train$prob_t_pred_log)
# summary(data_train$prob_t_pred_tree)
# summary(data_train$prob_t_pred_log - data_train$prob_t)
# summary(data_train$prob_t_pred_tree - data_train$prob_t)
rm(model)
##########################################################################################################
# Binarization of the columns
##########################################################################################################
#First we turn each continues column into a categorical feature with 4 different levels depending on the quantile that value falls in
data_train_enc <- binarize(data_train, names(data_train), d)
data_test_enc <- binarize(data_test, names(data_test), d)
View(data_train)
View(data_train_enc)
qnorm(0.1,0,1)
qnorm(0.2,0,1)
qnorm(0.3,0,1)
qnorm(0.4,0,1)
knitr::opts_chunk$set(echo = TRUE,message = FALSE,warning = FALSE )
library(kableExtra)
library(png)
library(ggplot2)
library(reshape2)
library(egg)
require(tidyr)
require(dplyr)
library(dplyr)
library(latex2exp)
# library(ggpubr)
library(data.table)
library(RColorBrewer)
library(MASS)
require(scales)
rm(list=ls())
# data1= read.csv('./../DataSets/compas.csv', header=TRUE, sep=',', na.strings="", stringsAsFactors =TRUE)
data= read.csv('./../Results/Dec 29/FlowOCT Kamiran_version/Kamiran_compas.csv', header=TRUE, sep=',', na.strings="", stringsAsFactors =TRUE)
data_name = 'default'
header= read.csv('./../header_kamiran.csv', header=TRUE, sep=',', na.strings="", stringsAsFactors =TRUE)
names(data) <- names(header)
rm(header)
# data = data[data$sample %in% c(2) ,]
# data = data[data$fair.bound!=1,]
forpres=FALSE
if (forpres){
fontfam = "sans"
} else {
fontfam = "serif"
}
figure_path = "./"
data$sample <- as.factor(data$sample)
# data$depth <- as.factor(data$depth)
data$fair.type <- as.factor(data$fair.type)
data$fair.bound <- as.factor(data$fair.bound)
tmp_none <- data[data$fair.type == 'None',]
tmp_none$fair.type = 'SP'
data = rbind(data,tmp_none)
data <- data[data$fair.type!= 'None',]
data$fair.type <- droplevels(data$fair.type)
rm(tmp_none)
# data$data <- data_name
knitr::opts_chunk$set(echo = TRUE,message = FALSE,warning = FALSE )
library(kableExtra)
library(png)
library(ggplot2)
library(reshape2)
library(egg)
require(tidyr)
require(dplyr)
library(dplyr)
library(latex2exp)
# library(ggpubr)
library(data.table)
library(RColorBrewer)
library(MASS)
require(scales)
rm(list=ls())
# data1= read.csv('./../DataSets/compas.csv', header=TRUE, sep=',', na.strings="", stringsAsFactors =TRUE)
data= read.csv('./../Results/Dec 29/FlowOCT Kamiran_version/Kamiran_compas.csv', header=TRUE, sep=',', na.strings="", stringsAsFactors =TRUE)
data_name = 'compas'
header= read.csv('./../header_kamiran.csv', header=TRUE, sep=',', na.strings="", stringsAsFactors =TRUE)
names(data) <- names(header)
rm(header)
# data = data[data$sample %in% c(2) ,]
# data = data[data$fair.bound!=1,]
forpres=FALSE
if (forpres){
fontfam = "sans"
} else {
fontfam = "serif"
}
figure_path = "./"
data$sample <- as.factor(data$sample)
# data$depth <- as.factor(data$depth)
data$fair.type <- as.factor(data$fair.type)
data$fair.bound <- as.factor(data$fair.bound)
tmp_none <- data[data$fair.type == 'None',]
tmp_none$fair.type = 'SP'
data = rbind(data,tmp_none)
data <- data[data$fair.type!= 'None',]
data$fair.type <- droplevels(data$fair.type)
rm(tmp_none)
# data$data <- data_name
tmp <- data[,c("approach",'sample',"depth","fair.bound","train.acc",'test.acc',
"sp.train.pred","sp.test.pred")]
tmp <- tmp %>%
group_by(approach,depth, fair.bound) %>%
summarise(mean(train.acc),mean(test.acc), mean(sp.train.pred),
mean(sp.test.pred))
names(tmp) <- c("approach","depth","fair.bound","train.acc",'test.acc',
"train.disc","test.disc")
tmp$fair.bound <- as.numeric(as.character(tmp$fair.bound))
tmp1 <- tmp[,c("approach","depth","fair.bound","test.acc","test.disc")]
tmp1$source <- 'out-of-sample'
names(tmp1) <- c("approach","depth","fair.bound","acc","disc",'source')
tmp2 <- tmp[,c("approach","depth","fair.bound","train.acc","train.disc")]
tmp2$source <- 'in-sample'
names(tmp2) <- c("approach","depth","fair.bound","acc","disc",'source')
tmp <- rbind(tmp1,tmp2)
rm(tmp1,tmp2)
data_flow <- tmp
data_flow$data <- NULL
rm(tmp,data)
data= read.csv('./../Results/Kamiran/compas.csv', header=TRUE, sep=',', na.strings="", stringsAsFactors =TRUE)
data$depth <- data$depth + 1
data <- data %>%
group_by(depth, fair.bound) %>%
summarise(mean(acc_tr_pre),mean(disc_tr_pre),mean(acc_te_pre), mean(disc_te_pre),
mean(train.acc),mean(sp.train.pred),mean(test.acc),mean(sp.test.pred))
names(data) <- c("depth","fair.bound",'acc_tr_pre','disc_tr_pre','acc_te_pre','disc_te_pre','train.acc','sp.train.pred','test.acc','sp.test.pred')
data$approach <- 'Kamiran_relab'
data_relab <- data[,c('approach','depth','fair.bound','train.acc','sp.train.pred','test.acc','sp.test.pred')]
# data_relab$approach <- 'Kamiran_relab'
data_relab_train <- data_relab[,c('approach','depth','fair.bound','train.acc','sp.train.pred')]
data_relab_train$source <- 'in-sample'
names(data_relab_train) <- c('approach','depth','fair.bound','acc','disc','source')
data_relab_test <- data_relab[,c('approach','depth','fair.bound','test.acc','sp.test.pred')]
data_relab_test$source <- 'out-of-sample'
names(data_relab_test) <- c('approach','depth','fair.bound','acc','disc','source')
data_relab <- rbind(data_relab_train, data_relab_test)
rm(data_relab_test, data_relab_train)
data_pre <- data[,c('approach','depth','fair.bound','acc_tr_pre','disc_tr_pre','acc_te_pre','disc_te_pre')]
data_pre_train <- data_pre[,c('approach','depth','fair.bound','acc_tr_pre','disc_tr_pre')]
data_pre_train$source <- 'in-sample'
names(data_pre_train) <- c('approach','depth','fair.bound','acc','disc','source')
data_pre_test <- data_pre[,c('approach','depth','fair.bound','acc_te_pre','disc_te_pre')]
data_pre_test$source <- 'out-of-sample'
names(data_pre_test) <- c('approach','depth','fair.bound','acc','disc','source')
data_pre <- rbind(data_pre_train, data_pre_test)
rm(data_pre_test, data_pre_train, data)
data_pre$fair.bound <- 1
data_pre <- unique(data_pre)
data_kamiran <- rbind(data_pre, data_relab)
rm(data_pre, data_relab)
data_kamiran$acc <- data_kamiran$acc/100
View(data_flow)
unique(data_flow$fair.bound)
knitr::opts_chunk$set(echo = TRUE,message = FALSE,warning = FALSE )
library(kableExtra)
library(png)
library(ggplot2)
library(reshape2)
library(egg)
require(tidyr)
require(dplyr)
library(dplyr)
library(latex2exp)
# library(ggpubr)
library(data.table)
library(RColorBrewer)
library(MASS)
require(scales)
rm(list=ls())
# data1= read.csv('./../DataSets/compas.csv', header=TRUE, sep=',', na.strings="", stringsAsFactors =TRUE)
data= read.csv('./../Results/Dec 29/FlowOCT/FlowOCT_limited-adult.csv', header=FALSE, sep=',', na.strings="", stringsAsFactors =TRUE)
data_name = 'limited-adult'
header= read.csv('./../header.csv', header=TRUE, sep=',', na.strings="", stringsAsFactors =TRUE)
names(data) <- names(header)
rm(header)
# data = data[data$sample %in% c(2) ,]
# data = data[data$fair.bound!=1,]
forpres=FALSE
if (forpres){
fontfam = "sans"
} else {
fontfam = "serif"
}
figure_path = "./"
data$sample <- as.factor(data$sample)
data$depth <- as.factor(data$depth)
data$fair.type <- as.factor(data$fair.type)
data$fair.bound <- as.factor(data$fair.bound)
for(i in c('SP','PE','EOpp','EOdds')){#'SP','CSP','PE','EOpp','EOdds'
tmp_none <- data[data$fair.type == 'None',]
tmp_none$fair.type = i
data = rbind(data,tmp_none)
}
data <- data[data$fair.type!= 'None',]
data$fair.type <- droplevels(data$fair.type)
rm(tmp_none)
data$data <- data_name
tmp <- data
tmp <- tmp %>%
group_by(approach,data,depth, fair.type, fair.bound) %>%
summarise(mean(train.acc),mean(test.acc),mean(sp.train.data), mean(sp.train.pred),
mean(sp.test.data),mean(sp.test.pred),
mean(csp.train.data), mean(csp.train.pred),
mean(csp.test.data),mean(csp.test.pred),
mean(pe.train.pred),
mean(pe.test.pred),
mean(EOpp.train.pred),
mean(EOpp.test.pred),
mean(EOdds.train.pred),
mean(EOdds.test.pred))
names(tmp) <- c("approach","data","depth","fair.type","fair.bound","train.acc",'test.acc',
"train.data.sp","train.pred.sp","test.data.sp","test.pred.sp",
"train.data.csp","train.pred.csp","test.data.csp","test.pred.csp",
"train.pred.pe","test.pred.pe",
"train.pred.EOpp","test.pred.EOpp",
"train.pred.EOdds","test.pred.EOdds")
metric = 'EOdds'
if(metric == 'SP'){
tmp <- subset(tmp, tmp$fair.type == metric)
tmp <- tmp[c("approach","data","depth","fair.type","fair.bound","test.acc",'train.acc',
'test.pred.sp','train.pred.sp')]
x_title = "Statistical Parity (%)"
y_title= "Accuracy (%)"
legend_title = 'SP Bound'
}else if(metric == 'CSP'){
tmp <- subset(tmp, tmp$fair.type == metric)
tmp <- tmp[c("approach","data","depth","fair.type","fair.bound","test.acc",'train.acc',
'test.pred.csp','train.pred.csp')]
x_title = "Conditional Statistical Parity (%)"
y_title= "Accuracy (%)"
legend_title = 'CSP Bound'
}else if(metric == 'PE'){
tmp <- subset(tmp, tmp$fair.type == metric)
tmp <- tmp[c("approach","data","depth","fair.type","fair.bound","test.acc",'train.acc',
'test.pred.pe','train.pred.pe')]
x_title = "Predictive Equality (%)"
y_title= "Accuracy (%)"
legend_title = 'PE Bound'
}else if(metric == 'EOpp'){
tmp <- subset(tmp, tmp$fair.type == metric)
tmp <- tmp[c("approach","data","depth","fair.type","fair.bound","test.acc",'train.acc',
'test.pred.EOpp','train.pred.EOpp')]
x_title = "Equal Opportunity (%)"
y_title= "Accuracy (%)"
legend_title = 'EOpp Bound'
}else if(metric == 'EOdds'){
tmp <- subset(tmp, tmp$fair.type == metric)
tmp <- tmp[c("approach","data","depth","fair.type","fair.bound","test.acc",'train.acc',
'test.pred.EOdds','train.pred.EOdds')]
x_title = "Equalized Odds (%)"
y_title= "Accuracy (%)"
legend_title = 'EOdds Bound'
}
names(tmp) <- c("approach","data","depth","fair.type","fair.bound","test.acc","train.acc","test.pred.disc","train.pred.disc")
# tmp$fair.type <- factor(tmp$fair.type, levels = c('SP','CSP','PE','EOpp','EOdds'))
tmp$fair.bound <- as.numeric(as.character(tmp$fair.bound))
tmp1 <- tmp[,c("approach","data","depth","fair.type","fair.bound","test.acc","test.pred.disc")]
tmp1$source <- 'out-of-sample'
names(tmp1) <- c("approach","data","depth","fair.type","fair.bound","acc","disc",'source')
tmp2 <- tmp[,c("approach","data","depth","fair.type","fair.bound","train.acc","train.pred.disc")]
tmp2$source <- 'in-sample'
names(tmp2) <- c("approach","data","depth","fair.type","fair.bound","acc","disc",'source')
tmp <- rbind(tmp1,tmp2)
rm(tmp1,tmp2)
View(tmp)
unique(tmp$fair.bound)
library(caret)
library(stringr)
library(outliers)
library(editrules)
library(dplyr)
rm(list=ls())
graphics.off()
Kamiran_version = TRUE
rm(list=ls())
graphics.off()
library(caret)
library(stringr)
library(outliers)
library(editrules)
library(dplyr)
rm(list=ls())
graphics.off()
Kamiran_version = TRUE
#################################################################################################
#Functions
#################################################################################################
dataencoder <- function (data) {
#encoding data
must_convert<-sapply(data,is.factor)       # logical vector telling if a variable needs to be displayed as numeric
M2<-sapply(data[,must_convert],unclass)    # data.frame of all categorical variables now displayed as numeric
data_num<-cbind(data[,!must_convert],M2)
data_num <- as.data.frame(data_num)
for(tmp_f in names(data)){
data_num[[tmp_f]] = as.factor(data_num[[tmp_f]] )
data_num[[tmp_f]]  = droplevels(data_num[[tmp_f]] )
}
data_num
}
##########################################################################################################
# read data
##########################################################################################################
setwd('/Users/sina/Documents/GitHub/FairStrongTrees/Data Proprocess code/adult/')
data_1 <- read.csv("adult.data", header = FALSE, sep = ",",na.strings = "",stringsAsFactors = TRUE)
data_2 <- read.csv("adult.test", header = FALSE, sep = ",",na.strings = "",stringsAsFactors = TRUE)
# data <- rbind(data_1,data_2)
data <- data_1
rm(data_1,data_2)
names(data) <- c('age','workclass','fnlwgt','education','education_num','marital_status','occupation','relationship',
'race','sex','capital_gain','capital_loss','hours_per_week','native_country','target')
# Let's replace ? with NA and omit them from the dataset
data[data==' ?'] = NA
data <- na.omit(data)
##########################################################################################################
# tidy preprocess
##########################################################################################################
# Check relationship between education and education.num
data %>% distinct(education, education_num)
# drop education.num variable
data$education_num <- NULL
# Create capital variable which is the difference betwwen capital-gain and capital-loss
data <- data %>% mutate(capital = capital_gain - capital_loss)
# List down Factor Columns in dataframe & Trim string in factor columns
fac_cols <- sapply(data, is.factor)
data <- data.frame(cbind(sapply(data[,fac_cols], trimws, which="both"), data[,!fac_cols]))
# Clean “Workclass” variable by categorizing it into 4 categories: Gov, Self-emp, Private and Other
data <- data %>% mutate(workclass = ifelse(grepl(".gov$", str_trim(workclass)), "Gov",
ifelse(grepl("^Self.",str_trim(workclass)),"Self-emp",
ifelse(grepl("^Private$", str_trim(workclass)),"Private", "Other"))))
data$workclass <- as.factor(data$workclass)
levels(data$workclass)
# Clean “Education” variable by categorizing it into groups: Before-Highschool, Associate, Post-graduate, HS-grad, Some-college and Bachelors
data <- data %>% mutate(education = ifelse(grepl(".th$|^Preschool$", (education)), "Before-Highschool",
ifelse(grepl("^Assoc.", (education)),"Associate",
ifelse(grepl("^Masters$|^Doctorate$|^Pro.",(education)), "Post-Graduate",
as.character((education))))))
data$education <- as.factor(data$education)
levels(data$education)
# Clean “Marital Status” variable
data <- data %>% mutate(marital_status = ifelse(grepl("^Married.", marital_status), "Married", as.character(marital_status)))
data$marital_status <- as.factor(data$marital_status)
levels(data$marital_status)
#Clean “Income variable”
data <- data %>% mutate(target = ifelse(grepl("^<=50K.$", target), "<=50K",
ifelse(grepl("^>50K.$", target),">50K", as.character(target))))
data$target <- as.factor(data$target)
levels(data$target)
# Categorize Age into 4 groups : <=30, 30-45, 45-60 and >60
# Convert Age character into numeric because Age has character type as default in dataset.
data$age <- as.integer(data$age)
# Categorize Age into 4 groups
data<- data %>% mutate(age_group = ifelse(age <=30, "<=30",
ifelse(age>30 & age <=45, "30-45",
ifelse(age>45 & age <=60,"45-60",
">60"))))
data$age_group <- factor(data$age_group, levels = c('<=30','30-45','45-60','>60'))
# Check levels result of Age after processing
levels(data$age_group)
#Clean Native Countries variable by categorizing it into two groups : US and Non-US
data<- data %>% mutate(native_country = ifelse(grepl("United.",native_country), "USA", "Non-USA"))
data$native_country <- as.factor(data$native_country)
levels(data$native_country)
# The quantiles of hours.per.weak are not unique; Here we divide people into following categories
data<- data %>% mutate(hours_per_week = ifelse(hours_per_week <=20, "<=20",
ifelse(hours_per_week>20 & hours_per_week <=40, "20-40",
ifelse(hours_per_week>40 & hours_per_week <=60,"40-60",
">60"))))
data$hours_per_week <- factor(data$hours_per_week, levels = c('<=20','20-40','40-60','>60'))
# fnlwgt
x='fnlwgt'
data[[x]] = as.numeric(data[[x]])
data[[x]] = cut(data[[x]],
c(-Inf,quantile(data[[x]],0.25),quantile(data[[x]],0.5),quantile(data[[x]],0.75),Inf),
labels=c(1,2,3,4))
# #Capital
summary(data$capital)
nrow(subset(data,data$capital>0))/nrow(data)
nrow(subset(data,data$capital<0))/nrow(data)
nrow(subset(data,data$capital==0))/nrow(data)
data<- data %>% mutate(capital = ifelse(capital < 0 , "<0",
ifelse(capital>0 , ">0",
'=0')))
data$age <- NULL
data$capital_gain <- NULL
data$capital_loss <- NULL
for(f in names(data)){
data[[f]] = as.factor(data[[f]])
}
##########################################################################################################
# One hot encoded data
##########################################################################################################
data<- dataencoder(data)
data_enc = data
#Now we tuurn all categorical  features into one-hot vectors
dmy <- dummyVars(" ~ .-target", data = data_enc)
data_enc <- data.frame(predict(dmy, newdata = data_enc))
#if a feature has only two levels we should only keep one column
#As our convention, we always keep the first one
cols = c()
tmp <- gsub("\\..*","",names( data_enc ))
for(name in names(data)){
# a = grepl( name , tmp ,fixed=TRUE)
a = tmp == name
if(sum(a)==2){
cols <- append(cols, min(which(a == TRUE)))
}else{
cols <- append(cols, which(a == TRUE))
}
}
data_enc <- data_enc[,cols]
data_enc$target <- data$target
# Taking care of  the integer columns : If x_ij = 1 then x_i(j+1) should be one as well  for odd i's
features = c('fnlwgt','hours_per_week','capital','age_group')
for(v in features){
for(i in seq(2,nlevels(data[[v]]),1)){
a =  as.numeric(as.character(data_enc[[paste(v,toString(i),sep = ".")]]))
b =  as.numeric(as.character(data_enc[[paste(v,toString(i-1),sep = ".")]]))
data_enc[[paste(v,toString(i),sep = ".")]] =  as.numeric(a|b)
}
}
rm(dmy)
setwd('/Users/sina/Documents/GitHub/FairStrongTrees/limited-adult-2/')
# write.csv(data,"adult.csv",row.names = FALSE)
# write.csv(data_enc,"adult_enc.csv",row.names = FALSE)
##########################################################################################################
# Sampling from data
##########################################################################################################
seeds = c(123,156,67,1,43)
for(Run in c(1,2,3,4,5)){
## set the seed to make your partition reproducible
set.seed(seeds[Run])
##########################################################################################################
# Splitting data into training and test
##########################################################################################################
# table(data$sex, data$target)
tmp <- data %>%
mutate(index = row_number()) %>%
group_by(sex, target) %>%
sample_frac(replace = FALSE, size = 0.75) %>%
ungroup()
train_ind <- tmp$index
data_test <- data[-train_ind, ]
data_test_enc <- data_enc[-train_ind, ]
tmp <- tmp %>%
sample_n(replace = FALSE, size = 2700)
train_ind <- tmp$index
data_train <- data[train_ind, ]
data_train_enc <- data_enc[train_ind, ]
tmp <- data_train %>%
mutate(index = row_number()) %>%
group_by(sex, target) %>%
sample_frac(replace = FALSE, size = 2/3)
train_calibration_ind <- tmp$index
data_train_calibration <- data_train[train_calibration_ind, ]
data_calibration<- data_train[-train_calibration_ind, ]
data_train_calibration_enc <- data_train_enc[train_calibration_ind, ]
data_calibration_enc <- data_train_enc[-train_calibration_ind, ]
print('#############################')
print(table(data_train_calibration$sex, data_train_calibration$target))
print(table(data_train$sex, data_train$target))
print(table(data_test$sex, data_test$target))
print(table(data_calibration$sex, data_calibration$target))
# Save files
write.csv(data_train_enc,paste("limited-adult-2_train_enc_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_test_enc,paste("limited-adult-2_test_enc_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_train,paste("limited-adult-2_train_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_test,paste("limited-adult-2_test_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_train_calibration,paste("limited-adult-2_train_calibration_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_train_calibration_enc,paste("limited-adult-2_train_calibration_enc_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_calibration,paste("limited-adult-2_calibration_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_calibration_enc,paste("limited-adult-2_calibration_enc_",toString(Run),".csv",sep=''),row.names = FALSE)
}
