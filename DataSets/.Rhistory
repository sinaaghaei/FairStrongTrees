print(table(data_train_calibration$race, data_train_calibration$priors_count  , data_train_calibration$target))
print(table(data_train$race, data_train$priors_count  , data_train$target))
print(table(data_test$race, data_test$priors_count  , data_test$target))
print(table(data_calibration$race, data_calibration$priors_count  , data_calibration$target))
#
# Save files
write.csv(data_train_enc,paste("compas_train_enc_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_test_enc,paste("compas_test_enc_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_train,paste("compas_train_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_test,paste("compas_test_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_train_calibration,paste("compas_train_calibration_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_train_calibration_enc,paste("compas_train_calibration_enc_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_calibration,paste("compas_calibration_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_calibration_enc,paste("compas_calibration_enc_",toString(Run),".csv",sep=''),row.names = FALSE)
}
# data_train<- read.csv("/Users/sina/Documents/GitHub/FairStrongTrees/DataSets/KamiranVersion/compas_train_calibration_1.csv", header = TRUE, sep = ",",na.strings = "",stringsAsFactors = TRUE)
# data_train_kamiran <- read.csv("/Users/sina/Documents/GitHub/FairStrongTrees/DataSets/KamiranVersion/compas_train_calibration_1.csv", header = TRUE, sep = ",",na.strings = "",stringsAsFactors = TRUE)
#
rm(list=ls())
library(data.table)
library(Publish)
library(caret)
library(sigmoid)
library(rpart)
library(dplyr)
rm(list=ls())
graphics.off()
Kamiran_version = TRUE
#################################################################################################
#Functions
#################################################################################################
dataencoder <- function (data) {
#encoding data
must_convert<-sapply(data,is.factor)       # logical vector telling if a variable needs to be displayed as numeric
M2<-sapply(data[,must_convert],unclass)    # data.frame of all categorical variables now displayed as numeric
data_num<-cbind(data[,!must_convert],M2)
data_num <- as.data.frame(data_num)
for(tmp_f in names(data)){
data_num[[tmp_f]] = as.factor(data_num[[tmp_f]] )
data_num[[tmp_f]]  = droplevels(data_num[[tmp_f]] )
}
data_num
}
##########################################################################################################
# read data
##########################################################################################################
# data_raw <- read.csv("compas-analysis-master/compas-scores-raw.csv", header = TRUE, sep = ",",na.strings = "",stringsAsFactors = TRUE)
# data_v <- read.csv("compas-analysis-master/compas-scores-two-years-violent.csv", header = TRUE, sep = ",",na.strings = "",stringsAsFactors = TRUE)
# data_compas <- read.csv("compas-analysis-master/compas-scores.csv", header = TRUE, sep = ",",na.strings = "",stringsAsFactors = TRUE)
setwd('/Users/sina/Documents/GitHub/FairStrongTrees/Data Proprocess code/compas/')
data <- read.csv("compas-analysis-master/compas-scores-two-years.csv", header = TRUE, sep = ",",na.strings = "",stringsAsFactors = TRUE)
#We remove decile_score, score_text from the features
data <- dplyr::select(data, race, age_cat, sex,priors_count, c_charge_degree, c_jail_in, c_jail_out, days_b_screening_arrest,
is_recid, two_year_recid) %>%
filter(days_b_screening_arrest <= 30) %>%
filter(days_b_screening_arrest >= -30) %>%
filter(is_recid != -1) %>%
filter(c_charge_degree != "O")
#  %>% filter(score_text != 'N/A')
data$length_of_stay <- as.numeric(as.Date(data$c_jail_out) - as.Date(data$c_jail_in))
data <- dplyr::select(data, race, age_cat, sex,priors_count, c_charge_degree,length_of_stay,
two_year_recid)
names(data)[names(data)=="two_year_recid"] = "target"
data$age_cat <- factor(data$age_cat, levels = c('Less than 25','25 - 45','Greater than 45'))
# data$score_text <- factor(data$score_text, levels = c('Low','Medium','High'))
# we partition prior convictions into
#four bins: 0, 1–2, 3–4, and 5 or more.
# see: https://arxiv.org/pdf/1701.08230.pdf
data$priors_count = as.numeric(data$priors_count)
data$priors_count = cut(data$priors_count ,
c(-Inf,0,2,4,Inf),
labels=c(1,2,3,4))
#5 bins: 0, 1, 2–7, 8-15,and 16 or more.
data$length_of_stay = cut(data$length_of_stay ,
c(-Inf,0,1,7,15,Inf),
labels=c(1,2,3,4,5))
index <- !(data$race %in% c('African-American','Caucasian','Hispanic'))
data$race[index] <- 'Other'
for(f in names(data)){
data[[f]] = as.factor(data[[f]])
data[[f]] = droplevels(data[[f]])
}
data$race <- as.character(data$race)
if(Kamiran_version){
index <- data$race == 'Caucasian'
data$race[index] = 'white'
data$race[!index] = 'non-white'
}
data$race <- as.factor(data$race)
##########################################################################################################
# encoding data
##########################################################################################################
data <- dataencoder(data)
data_enc = data
#Now we tuurn all categorical  features into one-hot vectors
dmy <- dummyVars(" ~ .-target", data = data_enc)
data_enc <- data.frame(predict(dmy, newdata = data_enc))
#if a feature has only two levels we should only keep one column
#As our convention, we always keep the first one
cols = c()
tmp <- gsub("\\..*","",names( data_enc ))
for(name in names(data)){
# a = grepl( name , tmp ,fixed=TRUE)
a = tmp == name
if(sum(a)==2){
cols <- append(cols, min(which(a == TRUE)))
}else{
cols <- append(cols, which(a == TRUE))
}
}
data_enc <- data_enc[,cols]
data_enc$target <- data$target
# Taking care of  the integer columns : If x_ij = 1 then x_i(j+1) should be one as well  for odd i's
features = c('age_cat','priors_count','length_of_stay')#,'score_text'
for(v in features){
for(i in seq(2,nlevels(data[[v]]),1)){
a =  as.numeric(as.character(data_enc[[paste(v,toString(i),sep = ".")]]))
b =  as.numeric(as.character(data_enc[[paste(v,toString(i-1),sep = ".")]]))
data_enc[[paste(v,toString(i),sep = ".")]] =  as.numeric(a|b)
}
}
rm(dmy)
if(Kamiran_version){
setwd('/Users/sina/Documents/GitHub/FairStrongTrees/DataSets/KamiranVersion')
}else{
setwd('/Users/sina/Documents/GitHub/FairStrongTrees/DataSets/')
}
write.csv(data,'compas.csv',row.names = FALSE)
write.csv(data_enc,'compas_enc.csv',row.names = FALSE)
##########################################################################################################
# Sampling from data
##########################################################################################################
seeds = c(123,156,67,1,43)
for(Run in c(1,2,3,4,5)){
## set the seed to make your partition reproducible
set.seed(seeds[Run])
##########################################################################################################
# Splitting data into training and test
##########################################################################################################
tmp <- data %>%
mutate(index = row_number()) %>%
group_by(race, priors_count, target) %>%
sample_frac(replace = FALSE, size = 0.75)
train_ind <- tmp$index
data_train <- data[train_ind, ]
data_test <- data[-train_ind, ]
data_train_enc <- data_enc[train_ind, ]
data_test_enc <- data_enc[-train_ind, ]
tmp <- data_train %>%
mutate(index = row_number()) %>%
group_by(race, priors_count, target) %>%
sample_frac(replace = FALSE, size = 2/3)
train_calibration_ind <- tmp$index
data_train_calibration <- data_train[train_calibration_ind, ]
data_calibration<- data_train[-train_calibration_ind, ]
data_train_calibration_enc <- data_train_enc[train_calibration_ind, ]
data_calibration_enc <- data_train_enc[-train_calibration_ind, ]
print('#############################')
print(table(data_train_calibration$race, data_train_calibration$priors_count  , data_train_calibration$target))
print(table(data_train$race, data_train$priors_count  , data_train$target))
print(table(data_test$race, data_test$priors_count  , data_test$target))
print(table(data_calibration$race, data_calibration$priors_count  , data_calibration$target))
#
# Save files
write.csv(data_train_enc,paste("compas_train_enc_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_test_enc,paste("compas_test_enc_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_train,paste("compas_train_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_test,paste("compas_test_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_train_calibration,paste("compas_train_calibration_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_train_calibration_enc,paste("compas_train_calibration_enc_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_calibration,paste("compas_calibration_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_calibration_enc,paste("compas_calibration_enc_",toString(Run),".csv",sep=''),row.names = FALSE)
}
# data_train<- read.csv("/Users/sina/Documents/GitHub/FairStrongTrees/DataSets/KamiranVersion/compas_train_calibration_1.csv", header = TRUE, sep = ",",na.strings = "",stringsAsFactors = TRUE)
# data_train_kamiran <- read.csv("/Users/sina/Documents/GitHub/FairStrongTrees/DataSets/KamiranVersion/compas_train_calibration_1.csv", header = TRUE, sep = ",",na.strings = "",stringsAsFactors = TRUE)
#
rm(list=ls())
library(caret)
library(stringr)
library(outliers)
library(editrules)
library(dplyr)
rm(list=ls())
graphics.off()
Kamiran_version = TRUE
#################################################################################################
#Functions
#################################################################################################
dataencoder <- function (data) {
#encoding data
must_convert<-sapply(data,is.factor)       # logical vector telling if a variable needs to be displayed as numeric
M2<-sapply(data[,must_convert],unclass)    # data.frame of all categorical variables now displayed as numeric
data_num<-cbind(data[,!must_convert],M2)
data_num <- as.data.frame(data_num)
for(tmp_f in names(data)){
data_num[[tmp_f]] = as.factor(data_num[[tmp_f]] )
data_num[[tmp_f]]  = droplevels(data_num[[tmp_f]] )
}
data_num
}
##########################################################################################################
# read data
##########################################################################################################
setwd('/Users/sina/Documents/GitHub/FairStrongTrees/Data Proprocess code/adult/')
data_1 <- read.csv("adult.data", header = FALSE, sep = ",",na.strings = "",stringsAsFactors = TRUE)
data_2 <- read.csv("adult.test", header = FALSE, sep = ",",na.strings = "",stringsAsFactors = TRUE)
# data <- rbind(data_1,data_2)
data <- data_1
rm(data_1,data_2)
names(data) <- c('age','workclass','fnlwgt','education','education_num','marital_status','occupation','relationship',
'race','sex','capital_gain','capital_loss','hours_per_week','native_country','target')
# Let's replace ? with NA and omit them from the dataset
data[data==' ?'] = NA
data <- na.omit(data)
##########################################################################################################
# tidy preprocess
##########################################################################################################
# Check relationship between education and education.num
data %>% distinct(education, education_num)
# drop education.num variable
data$education_num <- NULL
# Create capital variable which is the difference betwwen capital-gain and capital-loss
data <- data %>% mutate(capital = capital_gain - capital_loss)
# List down Factor Columns in dataframe & Trim string in factor columns
fac_cols <- sapply(data, is.factor)
data <- data.frame(cbind(sapply(data[,fac_cols], trimws, which="both"), data[,!fac_cols]))
# Clean “Workclass” variable by categorizing it into 4 categories: Gov, Self-emp, Private and Other
data <- data %>% mutate(workclass = ifelse(grepl(".gov$", str_trim(workclass)), "Gov",
ifelse(grepl("^Self.",str_trim(workclass)),"Self-emp",
ifelse(grepl("^Private$", str_trim(workclass)),"Private", "Other"))))
data$workclass <- as.factor(data$workclass)
levels(data$workclass)
# Clean “Education” variable by categorizing it into groups: Before-Highschool, Associate, Post-graduate, HS-grad, Some-college and Bachelors
data <- data %>% mutate(education = ifelse(grepl(".th$|^Preschool$", (education)), "Before-Highschool",
ifelse(grepl("^Assoc.", (education)),"Associate",
ifelse(grepl("^Masters$|^Doctorate$|^Pro.",(education)), "Post-Graduate",
as.character((education))))))
data$education <- as.factor(data$education)
levels(data$education)
# Clean “Marital Status” variable
data <- data %>% mutate(marital_status = ifelse(grepl("^Married.", marital_status), "Married", as.character(marital_status)))
data$marital_status <- as.factor(data$marital_status)
levels(data$marital_status)
#Clean “Income variable”
data <- data %>% mutate(target = ifelse(grepl("^<=50K.$", target), "<=50K",
ifelse(grepl("^>50K.$", target),">50K", as.character(target))))
data$target <- as.factor(data$target)
levels(data$target)
# Categorize Age into 4 groups : <=30, 30-45, 45-60 and >60
# Convert Age character into numeric because Age has character type as default in dataset.
data$age <- as.integer(data$age)
# Categorize Age into 4 groups
data<- data %>% mutate(age_group = ifelse(age <=30, "<=30",
ifelse(age>30 & age <=45, "30-45",
ifelse(age>45 & age <=60,"45-60",
">60"))))
data$age_group <- factor(data$age_group, levels = c('<=30','30-45','45-60','>60'))
# Check levels result of Age after processing
levels(data$age_group)
#Clean Native Countries variable by categorizing it into two groups : US and Non-US
data<- data %>% mutate(native_country = ifelse(grepl("United.",native_country), "USA", "Non-USA"))
data$native_country <- as.factor(data$native_country)
levels(data$native_country)
# The quantiles of hours.per.weak are not unique; Here we divide people into following categories
data<- data %>% mutate(hours_per_week = ifelse(hours_per_week <=20, "<=20",
ifelse(hours_per_week>20 & hours_per_week <=40, "20-40",
ifelse(hours_per_week>40 & hours_per_week <=60,"40-60",
">60"))))
data$hours_per_week <- factor(data$hours_per_week, levels = c('<=20','20-40','40-60','>60'))
# fnlwgt
x='fnlwgt'
data[[x]] = as.numeric(data[[x]])
data[[x]] = cut(data[[x]],
c(-Inf,quantile(data[[x]],0.25),quantile(data[[x]],0.5),quantile(data[[x]],0.75),Inf),
labels=c(1,2,3,4))
# #Capital
summary(data$capital)
nrow(subset(data,data$capital>0))/nrow(data)
nrow(subset(data,data$capital<0))/nrow(data)
nrow(subset(data,data$capital==0))/nrow(data)
data<- data %>% mutate(capital = ifelse(capital < 0 , "<0",
ifelse(capital>0 , ">0",
'=0')))
data$age <- NULL
data$capital_gain <- NULL
data$capital_loss <- NULL
for(f in names(data)){
data[[f]] = as.factor(data[[f]])
}
##########################################################################################################
# One hot encoded data
##########################################################################################################
data<- dataencoder(data)
data_enc = data
#Now we tuurn all categorical  features into one-hot vectors
dmy <- dummyVars(" ~ .-target", data = data_enc)
data_enc <- data.frame(predict(dmy, newdata = data_enc))
#if a feature has only two levels we should only keep one column
#As our convention, we always keep the first one
cols = c()
tmp <- gsub("\\..*","",names( data_enc ))
for(name in names(data)){
# a = grepl( name , tmp ,fixed=TRUE)
a = tmp == name
if(sum(a)==2){
cols <- append(cols, min(which(a == TRUE)))
}else{
cols <- append(cols, which(a == TRUE))
}
}
data_enc <- data_enc[,cols]
data_enc$target <- data$target
# Taking care of  the integer columns : If x_ij = 1 then x_i(j+1) should be one as well  for odd i's
features = c('fnlwgt','hours_per_week','capital','age_group')
for(v in features){
for(i in seq(2,nlevels(data[[v]]),1)){
a =  as.numeric(as.character(data_enc[[paste(v,toString(i),sep = ".")]]))
b =  as.numeric(as.character(data_enc[[paste(v,toString(i-1),sep = ".")]]))
data_enc[[paste(v,toString(i),sep = ".")]] =  as.numeric(a|b)
}
}
rm(dmy)
setwd('/Users/sina/Documents/GitHub/FairStrongTrees/DataSets/')
write.csv(data,"adult.csv",row.names = FALSE)
write.csv(data_enc,"adult_enc.csv",row.names = FALSE)
##########################################################################################################
# Sampling from data
##########################################################################################################
seeds = c(123,156,67,1,43)
for(Run in c(1,2,3,4,5)){
## set the seed to make your partition reproducible
set.seed(seeds[Run])
##########################################################################################################
# Splitting data into training and test
##########################################################################################################
# table(data$sex, data$target)
tmp <- data %>%
mutate(index = row_number()) %>%
group_by(sex, target) %>%
sample_frac(replace = FALSE, size = 0.75) %>%
ungroup()
tmp <- tmp %>%
sample_n(replace = FALSE, size = 5000)
train_ind <- tmp$index
data_train <- data[train_ind, ]
data_test <- data[-train_ind, ]
data_train_enc <- data_enc[train_ind, ]
data_test_enc <- data_enc[-train_ind, ]
tmp <- data_train %>%
mutate(index = row_number()) %>%
group_by(sex, target) %>%
sample_frac(replace = FALSE, size = 2/3)
train_calibration_ind <- tmp$index
data_train_calibration <- data_train[train_calibration_ind, ]
data_calibration<- data_train[-train_calibration_ind, ]
data_train_calibration_enc <- data_train_enc[train_calibration_ind, ]
data_calibration_enc <- data_train_enc[-train_calibration_ind, ]
print('#############################')
print(table(data_train_calibration$sex, data_train_calibration$target))
print(table(data_train$sex, data_train$target))
print(table(data_test$sex, data_test$target))
print(table(data_calibration$sex, data_calibration$target))
# Save files
write.csv(data_train_enc,paste("adult_train_enc_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_test_enc,paste("adult_test_enc_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_train,paste("adult_train_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_test,paste("adult_test_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_train_calibration,paste("adult_train_calibration_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_train_calibration_enc,paste("adult_train_calibration_enc_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_calibration,paste("adult_calibration_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_calibration_enc,paste("adult_calibration_enc_",toString(Run),".csv",sep=''),row.names = FALSE)
}
rm(list=ls())
library(caret)
library(stringr)
library(outliers)
library(editrules)
library(dplyr)
rm(list=ls())
graphics.off()
#################################################################################################
#Functions
#################################################################################################
dataencoder <- function (data) {
#encoding data
must_convert<-sapply(data,is.factor)       # logical vector telling if a variable needs to be displayed as numeric
M2<-sapply(data[,must_convert],unclass)    # data.frame of all categorical variables now displayed as numeric
data_num<-cbind(data[,!must_convert],M2)
data_num <- as.data.frame(data_num)
for(tmp_f in names(data)){
data_num[[tmp_f]] = as.factor(data_num[[tmp_f]] )
data_num[[tmp_f]]  = droplevels(data_num[[tmp_f]] )
}
data_num
}
##########################################################################################################
# read data
##########################################################################################################
setwd('/Users/sina/Documents/GitHub/FairStrongTrees/Data Proprocess code/default /')
data<- read.csv("default of credit card clients.csv", header = TRUE, sep = ",",na.strings = "",stringsAsFactors = TRUE)
##########################################################################################################
# tidy preprocess
##########################################################################################################
data$ID <- NULL
# This is the target column we are interested for classification
names(data)[names(data)=='default.payment.next.month'] = 'target'
#we can see that the repayment status is indicated in columns PAY_0, PAY_2 ... with no PAY_1 column,
#so we rename PAY_0 to PAY_1 for ease of understanding.
names(data)[names(data)=='PAY_0'] = 'PAY_1'
#we get rid of pay_amt and bill_amt columns as there is high correlation between these cols and the rest of the cols
data <- dplyr::select(data, LIMIT_BAL, SEX, EDUCATION, MARRIAGE, AGE, PAY_1, PAY_2, PAY_3,PAY_4,PAY_5,
PAY_6, target)
# Categorize Age into 4 groups : <=30, 30-45, 45-60 and >60
data<- data %>% mutate(age_group = ifelse(AGE <=30, "<=30",
ifelse(AGE>30 & AGE <=45, "30-45",
ifelse(AGE>45 & AGE <=60,"45-60",
">60"))))
data$age_group <- factor(data$age_group, levels = c('<=30','30-45','45-60','>60'))
data$AGE <- NULL
# LIMIT_BAL
x='LIMIT_BAL'
data[[x]] = as.numeric(data[[x]])
data[[x]] = cut(data[[x]],
c(-Inf,quantile(data[[x]],0.25),quantile(data[[x]],0.5),quantile(data[[x]],0.75),Inf),
labels=c(1,2,3,4))
for(f in names(data)){
data[[f]] = as.factor(data[[f]])
}
##########################################################################################################
# One hot encoded data
##########################################################################################################
data<- dataencoder(data)
data_enc = data
#Now we tuurn all categorical  features into one-hot vectors
dmy <- dummyVars(" ~ .-target", data = data_enc)
data_enc <- data.frame(predict(dmy, newdata = data_enc))
#if a feature has only two levels we should only keep one column
#As our convention, we always keep the first one
cols = c()
tmp <- gsub("\\..*","",names( data_enc ))
for(name in names(data)){
# a = grepl( name , tmp ,fixed=TRUE)
a = tmp == name
if(sum(a)==2){
cols <- append(cols, min(which(a == TRUE)))
}else{
cols <- append(cols, which(a == TRUE))
}
}
data_enc <- data_enc[,cols]
data_enc$target <- data$target
# Taking care of  the integer columns : If x_ij = 1 then x_i(j+1) should be one as well  for odd i's
features = c('LIMIT_BAL','age_group')#,'PAY_1','PAY_2','PAY_3','PAY_4','PAY_5','PAY_6'
for(v in features){
for(i in seq(2,nlevels(data[[v]]),1)){
a =  as.numeric(as.character(data_enc[[paste(v,toString(i),sep = ".")]]))
b =  as.numeric(as.character(data_enc[[paste(v,toString(i-1),sep = ".")]]))
data_enc[[paste(v,toString(i),sep = ".")]] =  as.numeric(a|b)
}
}
rm(dmy)
setwd('/Users/sina/Documents/GitHub/FairStrongTrees/DataSets/')
write.csv(data,"default.csv",row.names = FALSE)
write.csv(data_enc,"default_enc.csv",row.names = FALSE)
##########################################################################################################
# Sampling from data
##########################################################################################################
seeds = c(123,156,67,1,43)
for(Run in c(1,2,3,4,5)){
## set the seed to make your partition reproducible
set.seed(seeds[Run])
##########################################################################################################
# Splitting data into training and test
##########################################################################################################
# table(data$sex, data$target)
tmp <- data %>%
mutate(index = row_number()) %>%
group_by(SEX, target) %>%
sample_frac(replace = FALSE, size = 0.75) %>%
ungroup()
tmp <- tmp %>%
sample_n(replace = FALSE, size = 5000)
train_ind <- tmp$index
data_train <- data[train_ind, ]
data_test <- data[-train_ind, ]
data_train_enc <- data_enc[train_ind, ]
data_test_enc <- data_enc[-train_ind, ]
tmp <- data_train %>%
mutate(index = row_number()) %>%
group_by(SEX, target) %>%
sample_frac(replace = FALSE, size = 2/3)
train_calibration_ind <- tmp$index
data_train_calibration <- data_train[train_calibration_ind, ]
data_calibration<- data_train[-train_calibration_ind, ]
data_train_calibration_enc <- data_train_enc[train_calibration_ind, ]
data_calibration_enc <- data_train_enc[-train_calibration_ind, ]
print('#############################')
print(table(data_train_calibration$SEX, data_train_calibration$target))
print(table(data_train$SEX, data_train$target))
print(table(data_test$SEX, data_test$target))
print(table(data_calibration$SEX, data_calibration$target))
# Save files
write.csv(data_train_enc,paste("default_train_enc_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_test_enc,paste("default_test_enc_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_train,paste("default_train_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_test,paste("default_test_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_train_calibration,paste("default_train_calibration_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_train_calibration_enc,paste("default_train_calibration_enc_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_calibration,paste("default_calibration_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_calibration_enc,paste("default_calibration_enc_",toString(Run),".csv",sep=''),row.names = FALSE)
}
rm(list=ls())
