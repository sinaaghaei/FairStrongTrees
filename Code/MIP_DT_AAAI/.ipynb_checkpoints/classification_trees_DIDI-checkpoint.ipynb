{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames;\n",
    "using JuMP\n",
    "using Gurobi\n",
    "using CSV\n",
    "using JLD\n",
    "file_path = \"./../../DataSets/\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "# Arguments that we need from the user\n",
    "#####################################################\n",
    "data_group = \"compas\"; # or compas, adult, german\n",
    "train_file_name = \"compas_train_1.csv\";\n",
    "test_file_name  = \"compas_test_1.csv\";\n",
    "lambda = 0;\n",
    "depth = 1;\n",
    "time_limit = 100;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "# Reading data\n",
    "#####################################################\n",
    "data_train = CSV.read(file_path*train_file_name ,DataFrame);\n",
    "N_train = size(data_train,1);\n",
    "\n",
    "data_test = CSV.read(file_path*test_file_name ,DataFrame);\n",
    "N_test = size(data_test,1);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1543-element Vector{Int64}:\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " â‹®\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if data_group == \"compas\"\n",
    "    # Need to specify name of the column containing the class label and protected feature\n",
    "    class = :target; # name of the class label in the dataset\n",
    "    B = :race; # protected feautre\n",
    "\n",
    "    # Need to specify which column are categorical and which columns are non-categorical (quantitative)\n",
    "    # categorical features\n",
    "    F_c = [:sex,:c_charge_degree];\n",
    "    nf_c=size(F_c,1);\n",
    "\n",
    "    # quantitative features\n",
    "    F_q=[:age_cat,:priors_count,:length_of_stay];\n",
    "    nf_q=size(F_q,1);\n",
    "    \n",
    "    # We need the class label to be binary (0,1). In this data, the class lables are (1,2)\n",
    "    data_train[!,class] .-= 1;\n",
    "    data_test[!,class] .-= 1;\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ind (generic function with 1 method)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################################################\n",
    "#index function\n",
    "#####################################################\n",
    "function ind(x)\n",
    "    if x==true\n",
    "  1\n",
    "    else\n",
    "  0\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_tree (generic function with 1 method)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################################################\n",
    "#Tree structures\n",
    "#####################################################\n",
    "function get_tree(d)\n",
    "    nn = 2^d-1\n",
    "    nl = 2^d\n",
    "    \n",
    "    left=Vector{Array{Int64}}();\n",
    "    right = Vector{Array{Int64}}();\n",
    "    for n in 1:nn\n",
    "        crnt_depth = Int(floor(log(2,n)))\n",
    "        number_nodes_crnt_depth = 2^crnt_depth\n",
    "        num_leafs_under_n = 2^(d - crnt_depth)\n",
    "        \n",
    "        first_leaf_idx = (n-number_nodes_crnt_depth)*num_leafs_under_n+1\n",
    "        last_leaf_idx = first_leaf_idx+ num_leafs_under_n -1\n",
    "        mid_leaf_idx = Int(floor((first_leaf_idx+last_leaf_idx)/2))\n",
    "        n_lef = [first_leaf_idx:1:mid_leaf_idx;]\n",
    "        n_right = [mid_leaf_idx+1:1:last_leaf_idx;]\n",
    "        push!(left, n_lef);\n",
    "        push!(right, n_right);\n",
    "    end\n",
    "    \n",
    "    nn, nl, left, right\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_MIP_model (generic function with 1 method)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_MIP_model(nn, nl, left, right, data_train, B, class, F_c, F_q, lambda)\n",
    "    # In this model we assume the class labels in data_train are binary (0 and 1)\n",
    "    data = deepcopy(data_train);\n",
    "    N = size(data,1)\n",
    "\n",
    "    # Parameters\n",
    "    M=200;\n",
    "    M2=200;\n",
    "    ep=0.1;\n",
    "\n",
    "    fair = 1; # whether we have fairness penalty (fair=1) or not (fair=0)\n",
    "    if lambda ==0\n",
    "        fair = 0\n",
    "    end\n",
    "\n",
    "    ############################################\n",
    "    # Defining the decision variables\n",
    "    ############################################\n",
    "    model = Model()\n",
    "\n",
    "    # r[i,l] = |y_i - z_l|*x[i,l] which is the prediction error if i is assigned to l\n",
    "    # sum(r[i,l] for l=1:nl)=|y_i - yhat_i|\n",
    "    @variable(model, r[1:N,1:nl]>=0); \n",
    "\n",
    "    # x[i,l] denotes if datapoint i is assigned to leaf l\n",
    "    @variable(model, x[1:N,1:nl],Bin);\n",
    "\n",
    "    # ac[n,j]=1 means that we split on categorical feature j at node n\n",
    "    # in the paper we call this variable p[n,j]\n",
    "    @variable(model, ac[1:nn,F_c],Bin); \n",
    "\n",
    "    # aq[n,j]=1 means that we split on quantitative feature j at node n\n",
    "    @variable(model, aq[1:nn,F_q],Bin); \n",
    "\n",
    "    # b[n] is the cut-off value at node n if we split on quantitative features\n",
    "    @variable(model, b[1:nn]); \n",
    "\n",
    "    @variable(model, gp[1:N,1:nn]>=0);\n",
    "    @variable(model, gn[1:N,1:nn]>=0);\n",
    "\n",
    "    # if wq[i,n]=1 datapoint i should go left at node n; Also this means that we have splitted on a quantitative feature\n",
    "    @variable(model, wq[1:N,1:nn],Bin);\n",
    "\n",
    "    # if wc[i,n]=1 datapoint i should go left at node n; Also this means that we have splitted on a categorical feature\n",
    "    @variable(model, wc[1:N,1:nn],Bin);\n",
    "\n",
    "\n",
    "    @variable(model, s[1:nn,f in F_c, k in levels(data[!,f])],Bin);\n",
    "\n",
    "\n",
    "    # v[i,l] = |y_i- z_l|\n",
    "    @variable(model, v[1:N,1:nl]>=0); \n",
    "\n",
    "    #z_l is the binary prediction that we make at leaf node l\n",
    "    @variable(model, z[1:nl], Bin); \n",
    "\n",
    "\n",
    "    if fair == 1\n",
    "        # to linearize the prediction in the penalty function\n",
    "        # rp[i,l] = x[i,l]*z[l]\n",
    "        # sum(rp[i,l] for l=1:nl) = yhat_i\n",
    "        @variable(model, rp[1:N,1:nl]>=0); \n",
    "\n",
    "        #to linearize the absolute value in the penalty function\n",
    "        # rpp[y,xp] = |P(y) - P(y|xp)|\n",
    "        @variable(model, rpp[y in levels(data[!,class]), xp in levels(data[!,B])] >=0);\n",
    "    end;\n",
    "\n",
    "    ############################################\n",
    "    # objective\n",
    "    ############################################\n",
    "    if fair == 1\n",
    "        # 1/N*sum(|y_i - yhat_i| over i) + lambda* sum(|P(y) - P(y|xp)| over y and xp)\n",
    "        @objective(model, Min , (1-lambda)*(1/N)*sum(r[i,l] for i = 1:N , l=1:nl) +\n",
    "            lambda*(sum(rpp[y,xp] for y in levels(data[!,class]), xp in levels(data[!,B])) ) );\n",
    "    else\n",
    "        # 1/N*sum(|y_i - yhat_i| over i)\n",
    "        @objective(model, Min , (1/N)*sum(r[i,l] for i = 1:N , l=1:nl));\n",
    "    end;\n",
    "\n",
    "\n",
    "    ############################################\n",
    "    #Fairness constraints\n",
    "    ############################################\n",
    "    if fair == 1\n",
    "        # rpp[y,xp] = |P(y) - P(y|xp)|\n",
    "        for y in levels(data[!,class]), xp in levels(data[!,B])\n",
    "            # Let's |i: data[i,B]=xp|    \n",
    "            N_xp = size(data[(data[!,B] .== xp),:],1)\n",
    "            if (N_xp!= 0)\n",
    "            @constraint(model, sum(ind(sum(rp[i,l] for l=1:nl)==y) for i=1:N)/ N\n",
    "                             - sum(ind(sum(rp[i,l] for l=1:nl)==y) for i=1:N if (data[i,B]==xp) )/N_xp<= rpp[y,xp]);\n",
    "            @constraint(model, -sum(ind(sum(rp[i,l] for l=1:nl)==y) for i=1:N)/ N\n",
    "                               +sum(ind(sum(rp[i,l] for l=1:nl)==y) for i=1:N if (data[i,B]==xp) )/N_xp<= rpp[y,xp]);\n",
    "\n",
    "            end\n",
    "        end\n",
    "\n",
    "        # rp[i,l] = x[i,l]*z[l] so sum(rp[i,l] over l) = yhat_i\n",
    "        for i in 1:N, l in 1:nl\n",
    "            @constraint(model,rp[i,l]<=M2*x[i,l]);\n",
    "            @constraint(model,rp[i,l]<=z[l]);\n",
    "            @constraint(model,rp[i,l]>=z[l]-M2*(1-x[i,l]));\n",
    "        end\n",
    "    end;\n",
    "\n",
    "    ##############################################\n",
    "    # nodes constraints\n",
    "    ##############################################\n",
    "    for n in 1:nn\n",
    "        @constraint(model,sum(ac[n,f] for f in F_c)+sum(aq[n,f] for f in F_q)==1);\n",
    "    end\n",
    "\n",
    "\n",
    "    ##############################################\n",
    "    # categoricals\n",
    "    ##############################################\n",
    "    for n in 1:nn, f in F_c, k in levels(data[!,f])\n",
    "        @constraint(model,s[n,f,k] <= ac[n,f]);\n",
    "    end\n",
    "\n",
    "    for i in 1:N, n in 1:nn\n",
    "        @constraint(model,wc[i,n] == sum(sum(s[n,f,k]*ind(data[i,f]==k) for k in levels(data[!,f])) for f in F_c) );\n",
    "        for l in left[n]\n",
    "            @constraint(model,x[i,l] <= wc[i,n]+1-sum(ac[n,f] for f in F_c));\n",
    "        end\n",
    "        for l in right[n]\n",
    "            @constraint(model,x[i,l]<=1-wc[i,n]+1-sum(ac[n,f] for f in F_c));\n",
    "        end\n",
    "    end\n",
    "    ##############################################\n",
    "    # non categoricals\n",
    "    ##############################################\n",
    "    for i in 1:N, n in 1:nn\n",
    "        @constraint(model,b[n]-sum(aq[n,f]*data[i,f] for f in F_q) == gp[i,n]-gn[i,n]);\n",
    "        @constraint(model,gp[i,n]<=M*wq[i,n]);\n",
    "        @constraint(model,gn[i,n]<=M*(1-wq[i,n]));\n",
    "        @constraint(model,gp[i,n]+gn[i,n]>=ep*(1-wq[i,n])); \n",
    "        for l in right[n]\n",
    "            @constraint(model,x[i,l]<=1-wq[i,n]+1-sum(aq[n,f] for f in F_q));\n",
    "        end\n",
    "        for l in left[n]\n",
    "            @constraint(model,x[i,l]<=wq[i,n]+1-sum(aq[n,f] for f in F_q));\n",
    "        end\n",
    "    end\n",
    "    ##############################################\n",
    "    # linearize prediction error\n",
    "    ##############################################\n",
    "    for i in 1:N\n",
    "        @constraint(model,sum(x[i,l] for l=1:nl)==1);\n",
    "        for l in 1:nl\n",
    "            @constraint(model,r[i,l]<=M2*x[i,l]);\n",
    "            @constraint(model,r[i,l]<=v[i,l]);\n",
    "            @constraint(model,r[i,l]>=v[i,l]-M2*(1-x[i,l]));\n",
    "            @constraint(model,v[i,l]>=  data[i,class]-z[l]); \n",
    "            @constraint(model,v[i,l]>= -data[i,class]+z[l]); \n",
    "        end\n",
    "    end\n",
    "                                    \n",
    "    \n",
    "    model\n",
    "                                    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only - expires 2023-03-03\n",
      "Gurobi Optimizer version 9.1.0 build v9.1.0rc0 (mac64)\n",
      "Thread count: 2 physical cores, 4 logical processors, using up to 4 threads\n",
      "Optimize a model with 92585 rows, 46302 columns and 268495 nonzeros\n",
      "Model fingerprint: 0xa9e8d24f\n",
      "Variable types: 27775 continuous, 18527 integer (18527 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-01, 2e+02]\n",
      "  Objective range  [2e-04, 2e-04]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e-01, 2e+02]\n",
      "Found heuristic solution: objective 0.4549579\n",
      "Presolve removed 32403 rows and 13887 columns\n",
      "Presolve time: 0.64s\n",
      "Presolved: 60182 rows, 32415 columns, 208318 nonzeros\n",
      "Variable types: 9259 continuous, 23156 integer (23156 binary)\n",
      "\n",
      "Deterministic concurrent LP optimizer: primal and dual simplex\n",
      "Showing first log only...\n",
      "\n",
      "Concurrent spin time: 0.13s\n",
      "\n",
      "Solved with dual simplex\n",
      "\n",
      "Root relaxation: objective 0.000000e+00, 9622 iterations, 1.77 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    0.00000    0 9264    0.45496    0.00000   100%     -    4s\n",
      "     0     0    0.00000    0 9265    0.45496    0.00000   100%     -   11s\n",
      "     0     0    0.00000    0 9266    0.45496    0.00000   100%     -   17s\n",
      "     0     0    0.00000    0  206    0.45496    0.00000   100%     -   18s\n",
      "     0     0    0.00000    0  650    0.45496    0.00000   100%     -   18s\n",
      "     0     0    0.00000    0  650    0.45496    0.00000   100%     -   18s\n",
      "     0     0    0.00000    0  410    0.45496    0.00000   100%     -   19s\n",
      "     0     0    0.00000    0  211    0.45496    0.00000   100%     -   19s\n",
      "H    0     2                       0.4005185    0.00000   100%     -   19s\n",
      "     0     2    0.00000    0  211    0.40052    0.00000   100%     -   19s\n",
      "H    4     6                       0.3493195    0.00000   100%   933   19s\n",
      "   183    22    0.25162   16  414    0.34932    0.02635  92.5%   122   20s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 4\n",
      "  Cover: 86\n",
      "  Implied bound: 265\n",
      "  Flow cover: 134\n",
      "  Zero half: 42\n",
      "\n",
      "Explored 556 nodes (56746 simplex iterations) in 20.23 seconds\n",
      "Thread count was 4 (of 4 available processors)\n",
      "\n",
      "Solution count 3: 0.34932 0.400518 0.454958 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 3.493195074530e-01, best bound 3.493195074530e-01, gap 0.0000%\n",
      "\n",
      "User-callback calls 6101, time in user-callback 0.01 sec\n"
     ]
    }
   ],
   "source": [
    "# Let's build the model\n",
    "nn, nl, left, right = get_tree(depth);\n",
    "DT_model = get_MIP_model(nn, nl, left, right, data_train, B, class, F_c, F_q, lambda);\n",
    "\n",
    "# Let's solve the model\n",
    "set_optimizer_attribute(DT_model, \"TimeLimit\", time_limit);\n",
    "set_optimizer(DT_model, Gurobi.Optimizer);\n",
    "JuMP.optimize!(DT_model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "* Solver : Gurobi\n",
       "\n",
       "* Status\n",
       "  Result count       : 3\n",
       "  Termination status : OPTIMAL\n",
       "  Message from the solver:\n",
       "  \"Model was solved to optimality (subject to tolerances), and an optimal solution is available.\"\n",
       "\n",
       "* Candidate solution (result #1)\n",
       "  Primal status      : FEASIBLE_POINT\n",
       "  Dual status        : NO_SOLUTION\n",
       "  Objective value    : 3.49320e-01\n",
       "  Objective bound    : 3.49320e-01\n",
       "  Relative gap       : 0.00000e+00\n",
       "  Dual objective value : 3.49320e-01\n",
       "\n",
       "* Work counters\n",
       "  Solve time (sec)   : 2.02275e+01\n",
       "  Barrier iterations : 0\n",
       "  Node count         : 556\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution_summary(DT_model)\n",
    "objective_value(DT_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_metric (generic function with 1 method)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_data_DIDI(data_org,class,B)\n",
    "    data = deepcopy(data_org);\n",
    "    disc = 0\n",
    "    N = size(data,1)\n",
    "    for y in levels(data[!,class]), xp in levels(data[!,B]) \n",
    "        N_xp = size(data[(data[!,B] .== xp),:],1)\n",
    "        if (N_xp!= 0)\n",
    "            P_y = size(data[(data[!,class] .== y) ,:],1)/N\n",
    "            P_y_given_xp = size(data[(data[!,B] .== xp) .& (data[!,class] .== y) ,:],1)/N_xp\n",
    "            disc+= abs(P_y-P_y_given_xp)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    disc\n",
    "end\n",
    "\n",
    "function get_pred_DIDI(data_org,class,B,pred)\n",
    "    data = deepcopy(data_org);\n",
    "    data[!,:pred] = pred;\n",
    "    disc = 0\n",
    "    N = size(data,1)\n",
    "    for y in levels(data[!,class]), xp in levels(data[!,B]) \n",
    "        N_xp = size(data[(data[!,B] .== xp),:],1)\n",
    "        if (N_xp!= 0)\n",
    "            P_y = size(data[(data[!,:pred] .== y) ,:],1)/N\n",
    "            P_y_given_xp = size(data[(data[!,B] .== xp) .& (data[!,:pred] .== y) ,:],1)/N_xp\n",
    "            disc+= abs(P_y-P_y_given_xp)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    disc\n",
    "end\n",
    "\n",
    "function get_metric(nn,nl,left,right, ac, aq, b, s, z, time_limit, data_org, F_c, F_q)\n",
    "    data = deepcopy(data_org);\n",
    "    N = size(data,1)\n",
    "    \n",
    "    #####################################################################\n",
    "    model_pred = Model(Gurobi.Optimizer)\n",
    "    set_optimizer_attribute(model_pred, \"TimeLimit\", time_limit)\n",
    "    M=200;\n",
    "    M2=200;\n",
    "    ep=0.1;\n",
    "    #####################################################################\n",
    "    @variable(model_pred, x[1:N,1:nl],Bin);\n",
    "    @variable(model_pred, gp[1:N,1:nn]>=0);\n",
    "    @variable(model_pred, gn[1:N,1:nn]>=0);\n",
    "    @variable(model_pred, wq[1:N,1:nn],Bin);\n",
    "    @variable(model_pred, wc[1:N,1:nn],Bin);\n",
    "    \n",
    "    # routing constraints for categorical features\n",
    "    for i in 1:N,n in 1:nn\n",
    "        @constraint(model_pred,wc[i,n] == sum(sum(s[n,f,k]*ind(data[i,f]==k) for k in levels(data[!,f])) for f in F_c) );\n",
    "        for l in left[n]\n",
    "            @constraint(model_pred,x[i,l] <= wc[i,n]+1-sum(ac[n,f] for f in F_c));\n",
    "        end\n",
    "        for l in right[n]\n",
    "            @constraint(model_pred,x[i,l]<=1-wc[i,n]+1-sum(ac[n,f] for f in F_c));\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # routing constraints for non categoricals features\n",
    "    for i in 1:N, n in 1:nn\n",
    "        @constraint(model_pred,b[n]-sum(aq[n,f]*data[i,f] for f in F_q) == gp[i,n]-gn[i,n]);\n",
    "        @constraint(model_pred,gp[i,n]<=M*wq[i,n]);\n",
    "        @constraint(model_pred,gn[i,n]<=M*(1-wq[i,n]));\n",
    "        @constraint(model_pred,gp[i,n]+gn[i,n]>=ep*(1-wq[i,n])); #if b=criteria then w is 1 and go left\n",
    "        for l in right[n]\n",
    "            @constraint(model_pred,x[i,l]<=1-wq[i,n]+1-sum(aq[n,f] for f in F_q));\n",
    "        end\n",
    "        for l in left[n]\n",
    "            @constraint(model_pred,x[i,l]<=wq[i,n]+1-sum(aq[n,f] for f in F_q));\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    for i in 1:N\n",
    "        @constraint(model_pred,sum(x[i,l] for l=1:nl)==1);\n",
    "    end\n",
    "    #####################################################################\n",
    "    set_silent(model_pred)\n",
    "    optimize!(model_pred)\n",
    "    x = round.(JuMP.value.(x));\n",
    "    pred= x*z;\n",
    "    acc = sum(pred .== data[!,class])/N\n",
    "    DIDI = get_pred_DIDI(data,class,B,pred)\n",
    "\n",
    "    #####################################################################\n",
    "    acc, DIDI\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr_acc=\t0.6506804925469863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9004162181585729"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = round.(JuMP.value.(DT_model[:x]));\n",
    "z = round.(JuMP.value.(DT_model[:z]));\n",
    "pred= x*z;\n",
    "println(\"tr_acc=\\t\",sum(pred .== data_train[!,class])/N_train)\n",
    "DIDI = get_pred_DIDI(data_train,class,B,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = round.(JuMP.value.(DT_model[:ac]));\n",
    "aq = round.(JuMP.value.(DT_model[:aq]));\n",
    "b = JuMP.value.(DT_model[:b]);\n",
    "s = round.(JuMP.value.(DT_model[:s]));\n",
    "z = round.(JuMP.value.(DT_model[:z]));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6351325494276616"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data_DIDI(data_train,class,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only - expires 2023-03-03\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6506804925469863, 0.9004162181585729)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc,DIDI = get_metric(nn,nl,left,right, ac, aq, b, s, z, time_limit, data_train, F_c, F_q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6174482569699942"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data_DIDI(data_test,class,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only - expires 2023-03-03\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6493843162670123, 0.9319089462847763)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc,DIDI = get_metric(nn,nl,left,right, ac, aq, b, s, z, time_limit, data_test, F_c, F_q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
